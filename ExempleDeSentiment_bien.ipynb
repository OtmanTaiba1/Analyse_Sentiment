{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                         La premiere code 1 modele LogisticRegression                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=5000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de régression logistique\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model1.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit= {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    La Accuracy de cette code 1=86%                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# Calcul de l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit= {sentiment_predit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    code 2 modele SVM                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=30000000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle SVM\n",
    "model2 = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model2.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit= {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    La Accuracy de cette code 2=89%                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Calcul de l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            code 3 modele GradientBoostingClassifier(GBC)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=1000000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de GBM\n",
    "model3 = GradientBoostingClassifier()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model2.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit = {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit = {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                              La Accuracy de cette code 3 =65%                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "# Calcul de l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte\n",
    "def preprocessor_texte(texte):\n",
    "    texte = texte.lower()  # Conversion en minuscules\n",
    "    texte = re.sub(r'[^a-zA-Z\\s]', '', texte)  # Suppression de la ponctuation et des caractères spéciaux\n",
    "    tokens = word_tokenize(texte)  # Tokenisation\n",
    "    mots_vides = set(stopwords.words('english'))  # Mots vides en anglais\n",
    "    tokens = [mot for mot in tokens if mot not in mots_vides]  # Suppression des mots vides\n",
    "    lemmatiseur = WordNetLemmatizer()  # Lemmatisation\n",
    "    tokens = [lemmatiseur.lemmatize(mot) for mot in tokens]\n",
    "    texte_nettoye = ' '.join(tokens)  # Rejoindre les tokens en une seule chaîne de texte\n",
    "    return texte_nettoye\n",
    "\n",
    "# Prétraitement des données textuelles\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "# Création de l'objet TfidfVectorizer avec les paramètres souhaités\n",
    "vectoriseur = TfidfVectorizer(\n",
    "    lowercase=True,  # Conversion en minuscules\n",
    "    max_features=50000,  # Nombre maximal de fonctionnalités\n",
    "    stop_words='english',  # Mots vides en anglais\n",
    "    tokenizer=word_tokenize,  # Fonction de tokenisation\n",
    "    ngram_range=(1, 4)  # Utilisation de n-grammes de 1 à 3 mots\n",
    ")\n",
    "\n",
    "# Vectorisation du texte\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de GBM\n",
    "model3 = GradientBoostingClassifier()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données\n",
    "def predire_sentiment(texte):\n",
    "    texte = preprocessor_texte(texte)  # Prétraitement du texte\n",
    "    vecteur = vectoriseur.transform([texte])  # Vectorisation du texte\n",
    "    prediction = model3.predict(vecteur)[0]  # Prédiction du sentiment\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "print(f\"Sentiment prédit : {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "# Calcul de l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "\n",
    "# Importez vos bibliothèques et code ici\n",
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"review\"]\n",
    "labels_sentiment = data[\"sentiment\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=5000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de régression logistique\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model1.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "#nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "#\n",
    "# print(f\"la sentiment_predit= {sentiment_predit}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/result', methods=['POST'])\n",
    "def result():\n",
    "    texte = request.form['texte']\n",
    "    sentiment_predit = predire_sentiment(texte)\n",
    "    return render_template('result.html', texte=texte, sentiment_predit=sentiment_predit)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=30000000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle SVM\n",
    "model2 = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model2.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit = {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization du texte avec TF-IDF (utilisation du même vectorizer que pour les données d'entraînement)\n",
    "vecteurs_texte_test = vectoriseur.transform(X_test)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_test = model2.predict(vecteurs_texte_test)\n",
    "\n",
    "# Calcul de l'exactitude sur les données de test\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Accuracy on test data:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte\n",
    "def preprocessor_texte(texte):\n",
    "    texte = texte.lower()  # Conversion en minuscules\n",
    "    texte = re.sub(r'[^a-zA-Z\\s]', '', texte)  # Suppression de la ponctuation et des caractères spéciaux\n",
    "    tokens = word_tokenize(texte)  # Tokenisation\n",
    "    mots_vides = set(stopwords.words('english'))  # Mots vides en anglais\n",
    "    tokens = [mot for mot in tokens if mot not in mots_vides]  # Suppression des mots vides\n",
    "    lemmatiseur = WordNetLemmatizer()  # Lemmatisation\n",
    "    tokens = [lemmatiseur.lemmatize(mot) for mot in tokens]\n",
    "    texte_nettoye = ' '.join(tokens)  # Rejoindre les tokens en une seule chaîne de texte\n",
    "    return texte_nettoye\n",
    "\n",
    "# Prétraitement des données textuelles\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "# Création de l'objet TfidfVectorizer avec les paramètres souhaités\n",
    "vectoriseur = TfidfVectorizer(\n",
    "    lowercase=True,  # Conversion en minuscules\n",
    "    max_features=50000,  # Nombre maximal de fonctionnalités\n",
    "    stop_words='english',  # Mots vides en anglais\n",
    "    tokenizer=word_tokenize,  # Fonction de tokenisation\n",
    "    ngram_range=(1, 4)  # Utilisation de n-grammes de 1 à 3 mots\n",
    ")\n",
    "\n",
    "# Vectorisation du texte\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de GBM\n",
    "model3 = GradientBoostingClassifier()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données\n",
    "def predire_sentiment(texte):\n",
    "    texte = preprocessor_texte(texte)  # Prétraitement du texte\n",
    "    vecteur = vectoriseur.transform([texte])  # Vectorisation du texte\n",
    "    prediction = model3.predict(vecteur)[0]  # Prédiction du sentiment\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "print(f\"Sentiment prédit : {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "# Calcul de l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la sentiment_predit= negative\n"
     ]
    }
   ],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=5000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de régression logistique\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model1.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit= {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la sentiment_predit = positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=1000000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle de GBM\n",
    "model3 = GradientBoostingClassifier()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model3.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit = {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la sentiment_predit= negative\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Chargement du jeu de données (remplacez 'votre_data.csv' par votre chemin de fichier réel)\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Hypothèse : les colonnes \"texte\" et \"labels\" existent dans vos données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte (facultatif, personnalisez selon vos besoins)\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    blob = TextBlob(str(texte))  # Assurez-vous que le texte est de type str\n",
    "    # Minuscules, suppression de la ponctuation, stop words, etc.\n",
    "    texte = blob.lower().string.strip()\n",
    "    # Ajoutez d'autres étapes de prétraitement si nécessaire\n",
    "    return texte\n",
    "\n",
    "# Prétraiter les données textuelles (facultatif)\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=30000000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement d'un modèle SVM\n",
    "model2 = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Fonction pour prédire le sentiment sur de nouvelles données (facultatif)\n",
    "def predire_sentiment(texte):\n",
    "    \"\"\"Prédit le sentiment d'un nouveau texte\"\"\"\n",
    "    # Prétraiter le texte si nécessaire (cohérent avec les données d'entraînement)\n",
    "    texte = preprocessor_texte(texte)\n",
    "    vecteur = vectoriseur.transform([texte])\n",
    "    prediction = model2.predict(vecteur)[0]\n",
    "    return prediction\n",
    "\n",
    "# Exemple d'utilisation (remplacez 'nouveau_texte' par votre texte)\n",
    "nouveau_texte = input(\"Entrez le nouveau texte : \")\n",
    "sentiment_predit = predire_sentiment(nouveau_texte)\n",
    "\n",
    "print(f\"la sentiment_predit= {sentiment_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle avec noyau polynomial : 0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle SVM avec noyau polynomial\n",
    "model2 = SVC(kernel='poly', degree=2, C=1, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Calculer la précision\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Précision du modèle avec noyau polynomial : {precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle avec noyau RBF : 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle SVM avec noyau RBF\n",
    "model2 = SVC(kernel='rbf', C=2, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Calculer la précision\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Précision du modèle avec noyau RBF : {precision}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculer la précision\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(y_test, y_pred)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrécision du modèle avec noyau RBF : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle SVM avec noyau RBF\n",
    "model2 = SVC(kernel='rbf', C=2, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Calculer la précision\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Précision du modèle avec noyau RBF : {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Prédiction sur l'ensemble de test\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Calcul de l'exactitude\u001b[39;00m\n\u001b[0;32m      7\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Calcul de l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    Tester Les autres modeles avec autre Parametres                                      \n",
    "                                    donner les Meilleurs hyperparametres , les Meilleurs score ,                        \n",
    "                                    et Meilleurs modele avec deffirent testeur                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle : SVM\n",
      "Meilleurs hyperparamètres : {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Meilleur score sur les données de test : 0.896551724137931\n",
      "------------------------------\n",
      "Modèle : LogisticRegression\n",
      "Meilleurs hyperparamètres : {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Meilleur score sur les données de test : 0.896551724137931\n",
      "------------------------------\n",
      "Modèle : RandomForest\n",
      "Meilleurs hyperparamètres : {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Meilleur score sur les données de test : 0.8275862068965517\n",
      "------------------------------\n",
      "Modèle : GradientBoosting\n",
      "Meilleurs hyperparamètres : {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Meilleur score sur les données de test : 0.6551724137931034\n",
      "------------------------------\n",
      "Modèle : KNeighbors\n",
      "Meilleurs hyperparamètres : {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Meilleur score sur les données de test : 0.7931034482758621\n",
      "------------------------------\n",
      "Le meilleur modèle est SVM avec un score de 0.896551724137931\n",
      "Meilleurs hyperparamètres : {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\otman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.74426877 0.75296443 0.71857708 0.72727273 0.7715415  0.7715415\n",
      "        nan 0.53557312        nan 0.58735178        nan 0.61343874]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Assurez-vous que les colonnes \"text\" et \"tag\" existent dans les données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse\"\"\"\n",
    "    # Conversion en minuscule, suppression de la ponctuation et des stopwords\n",
    "    blob = TextBlob(str(texte))\n",
    "    texte = blob.lower().string.strip()\n",
    "    return texte\n",
    "\n",
    "# Prétraitement du texte\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=10000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèles à tester\n",
    "models = {\n",
    "\n",
    "    'SVM': SVC(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'KNeighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Grilles d'hyperparamètres à explorer pour chaque modèle\n",
    "param_grids = {\n",
    " \n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l2'],  # Utilisez uniquement 'l2' pour assurer la compatibilité avec les solveurs\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.01],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Stockage des meilleurs résultats\n",
    "best_model = None\n",
    "best_score = 0\n",
    "best_params = None\n",
    "best_model_name = None\n",
    "\n",
    "# Test de chaque modèle avec GridSearchCV\n",
    "for model_name, model in models.items():\n",
    "    # Initialisation de GridSearchCV avec le modèle, la grille d'hyperparamètres et le nombre de plis pour la validation croisée\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, n_jobs=-1)\n",
    "    \n",
    "    # Entraînement du modèle avec GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédiction et évaluation des performances\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Comparaison des scores et sauvegarde du meilleur modèle\n",
    "    if score > best_score:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_score = score\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model_name = model_name\n",
    "    \n",
    "    # Affichage des résultats pour chaque modèle\n",
    "    print(f\"Modèle : {model_name}\")\n",
    "    print(f\"Meilleurs hyperparamètres : {grid_search.best_params_}\")\n",
    "    print(f\"Meilleur score sur les données de test : {score}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Affichage du meilleur modèle global\n",
    "print(f\"Le meilleur modèle est {best_model_name} avec un score de {best_score}\")\n",
    "print(f\"Meilleurs hyperparamètres : {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Modèle  \\\n",
      "LogisticRegression  LogisticRegression   \n",
      "SVM                                SVM   \n",
      "RandomForest              RandomForest   \n",
      "GradientBoosting      GradientBoosting   \n",
      "KNeighbors                  KNeighbors   \n",
      "\n",
      "                                            Meilleurs hyperparamètres  \\\n",
      "LogisticRegression   {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}   \n",
      "SVM                    {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}   \n",
      "RandomForest        {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
      "GradientBoosting    {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
      "KNeighbors          {'metric': 'euclidean', 'n_neighbors': 7, 'wei...   \n",
      "\n",
      "                    Meilleur score sur les données de test  \n",
      "LogisticRegression                                0.896552  \n",
      "SVM                                               0.896552  \n",
      "RandomForest                                      0.827586  \n",
      "GradientBoosting                                  0.689655  \n",
      "KNeighbors                                        0.793103  \n",
      "\n",
      "Le meilleur modèle est LogisticRegression avec un score de 0.896551724137931\n",
      "Meilleurs hyperparamètres : {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\otman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.74426877 0.75296443 0.71857708 0.72727273 0.7715415  0.7715415\n",
      "        nan 0.53557312        nan 0.58735178        nan 0.61343874]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv(\"DataDoc.csv\")\n",
    "\n",
    "# Assurez-vous que les colonnes \"text\" et \"tag\" existent dans les données\n",
    "texte_data = data[\"text\"]\n",
    "labels_sentiment = data[\"tag\"]\n",
    "\n",
    "# Fonction pour prétraiter le texte\n",
    "def preprocessor_texte(texte):\n",
    "    \"\"\"Nettoie le texte avant l'analyse.\"\"\"\n",
    "    # Conversion en minuscules, suppression de la ponctuation, etc.\n",
    "    blob = TextBlob(str(texte))\n",
    "    texte = blob.lower().string.strip()\n",
    "    return texte\n",
    "\n",
    "# Prétraitement du texte\n",
    "texte_data = [preprocessor_texte(texte) for texte in texte_data]\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectoriseur = TfidfVectorizer(max_features=10000)\n",
    "vecteurs_texte = vectoriseur.fit_transform(texte_data)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vecteurs_texte, labels_sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèles à tester\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVM': SVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'KNeighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Grilles d'hyperparamètres à explorer pour chaque modèle\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.01],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dictionnaire pour stocker les résultats\n",
    "results_dict = {}\n",
    "\n",
    "# Test de chaque modèle avec GridSearchCV\n",
    "for model_name, model in models.items():\n",
    "    # Initialisation de GridSearchCV avec le modèle, la grille d'hyperparamètres et le nombre de plis pour la validation croisée\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, n_jobs=-1)\n",
    "    \n",
    "    # Entraînement du modèle avec GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédiction et évaluation des performances\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Stockage des résultats dans le dictionnaire\n",
    "    results_dict[model_name] = {\n",
    "        'Modèle': model_name,\n",
    "        'Meilleurs hyperparamètres': grid_search.best_params_,\n",
    "        'Meilleur score sur les données de test': score\n",
    "    }\n",
    "\n",
    "# Convertir les résultats en DataFrame pour afficher sous forme de tableau\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "\n",
    "# Afficher les résultats sous forme de tableau\n",
    "print(results_df)\n",
    "\n",
    "# Identifier et afficher le meilleur modèle global\n",
    "best_model_name = results_df['Meilleur score sur les données de test'].idxmax()\n",
    "print(f\"\\nLe meilleur modèle est {best_model_name} avec un score de {results_df.loc[best_model_name, 'Meilleur score sur les données de test']}\")\n",
    "print(f\"Meilleurs hyperparamètres : {results_df.loc[best_model_name, 'Meilleurs hyperparamètres']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: LogisticRegression\n",
      "Précision (Accuracy): 0.8620689655172413\n",
      "Précision (Precision): 0.8684922244759972\n",
      "Rappel (Recall): 0.8620689655172413\n",
      "Mesure F1 (F1-score): 0.8610742705570292\n",
      "ROC-AUC: 0.9095238095238095\n",
      "\n",
      "Rapport de classification pour le modèle:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.93      0.88        15\n",
      "    positive       0.92      0.79      0.85        14\n",
      "\n",
      "    accuracy                           0.86        29\n",
      "   macro avg       0.87      0.86      0.86        29\n",
      "weighted avg       0.87      0.86      0.86        29\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Modèle: SVM\n",
      "Précision (Accuracy): 0.8620689655172413\n",
      "Précision (Precision): 0.8684922244759972\n",
      "Rappel (Recall): 0.8620689655172413\n",
      "Mesure F1 (F1-score): 0.8610742705570292\n",
      "ROC-AUC: 0.9095238095238095\n",
      "\n",
      "Rapport de classification pour le modèle:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.93      0.88        15\n",
      "    positive       0.92      0.79      0.85        14\n",
      "\n",
      "    accuracy                           0.86        29\n",
      "   macro avg       0.87      0.86      0.86        29\n",
      "weighted avg       0.87      0.86      0.86        29\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Modèle: RandomForest\n",
      "Précision (Accuracy): 0.7931034482758621\n",
      "Précision (Precision): 0.8156079854809437\n",
      "Rappel (Recall): 0.7931034482758621\n",
      "Mesure F1 (F1-score): 0.7880324543610547\n",
      "ROC-AUC: 0.8666666666666667\n",
      "\n",
      "Rapport de classification pour le modèle:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.93      0.82        15\n",
      "    positive       0.90      0.64      0.75        14\n",
      "\n",
      "    accuracy                           0.79        29\n",
      "   macro avg       0.82      0.79      0.79        29\n",
      "weighted avg       0.82      0.79      0.79        29\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Modèle: GradientBoosting\n",
      "Précision (Accuracy): 0.6551724137931034\n",
      "Précision (Precision): 0.6551724137931034\n",
      "Rappel (Recall): 0.6551724137931034\n",
      "Mesure F1 (F1-score): 0.6551724137931034\n",
      "ROC-AUC: 0.7476190476190476\n",
      "\n",
      "Rapport de classification pour le modèle:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        15\n",
      "    positive       0.64      0.64      0.64        14\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.65      0.65      0.65        29\n",
      "weighted avg       0.66      0.66      0.66        29\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Modèle: KNeighbors\n",
      "Précision (Accuracy): 0.7931034482758621\n",
      "Précision (Precision): 0.7997347480106101\n",
      "Rappel (Recall): 0.7931034482758621\n",
      "Mesure F1 (F1-score): 0.7926108374384238\n",
      "ROC-AUC: 0.8428571428571427\n",
      "\n",
      "Rapport de classification pour le modèle:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.79        15\n",
      "    positive       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.79        29\n",
      "   macro avg       0.80      0.80      0.79        29\n",
      "weighted avg       0.80      0.79      0.79        29\n",
      "\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les modèles et les métriques\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Modèles à tester\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'KNeighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Calculer les métriques pour chaque modèle\n",
    "for model_name, model in models.items():\n",
    "    # Entraîner le modèle sur les données d'entraînement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Effectuer des prédictions sur les données de test\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculer les métriques d'évaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Afficher les métriques d'évaluation\n",
    "    print(f\"Modèle: {model_name}\")\n",
    "    print(\"Précision (Accuracy):\", accuracy)\n",
    "    print(\"Précision (Precision):\", precision)\n",
    "    print(\"Rappel (Recall):\", recall)\n",
    "    print(\"Mesure F1 (F1-score):\", f1)\n",
    "    \n",
    "    # Calculer et afficher le score ROC-AUC (si applicable)\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilités de la classe positive\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(\"ROC-AUC:\", roc_auc)\n",
    "    except AttributeError:\n",
    "        print(\"Le modèle ne supporte pas predict_proba ou decision_function.\")\n",
    "    \n",
    "    # Afficher le rapport de classification complet\n",
    "    print(\"\\nRapport de classification pour le modèle:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
